# Content
- [Request Response](#request-response)
- [Synchronous vs Asynchronous workloads](#synchronous-vs-asynchronous-workloads)
- [Push](#push)
- [Short Polling](#short-polling)
- [Long Polling](#long-polling)
- [Publish Subcribe (Pub/Sub)](#publish-subcribe)

# Request Response
1. **Client** sends a **Request**.
  - In **TCP**, the data that the **Client** send is a continuous stream of data. Data may be serialized.
2. **Server** parses the **Request**
  - **Server** needs to parse the data to look for the start and end of a **Request**.
3. **Server** processes the **Request**
  - De-serialization may be needed.
4. **Server** sends a **Response**
5. **Client** parses the Response and consume.

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/7c030a09-6dfd-437b-9cbd-0ea32a0e8178)

## Where it is used?
- Web, HTTP, DNS, SSH
- RPC (Remote Procedure Call)
- SQL and Database Protocols
- APIs (REST/SOAP/GraphQL)

## Anatomy of a Request / Response
- A request structure is defined by both client and server. And they both have to agree on it based on the protocol being used.
- Request has a boundary and it is defined by a protocol and message format.


A GET HTTP Request structure.
```
GET HTTP/1.1
Headers
<CRLF>
BODY
```

For large requests, there are two options to send data.
- Send the entire large request (Simple)
- Send chunked requests (Efficient and resumable)

## Doesn't work everywhere
- Notification service
- Chatting application
- Very long-running request

# Synchronous vs Asynchronous workloads
## Synchronous I/O
- Caller sends a request and blocks.
- Caller cannot exeucute any code meanwhile.
- Receiver responds, Callers unblocks.
- Caller and Receiver are in "Sync".

### Example of an OS synchronous I/O
- Program asks OS to read form disk.
- Program main thread is taken off of the CPU.
- Read completes, program can resume execution.

## Asynchronous I/O
- Caller sends a request.
- Caller can work until it gets a response.
- Call either:
  - Checks if the response is ready (epoll).
  - Receiver calls back when it's done (io_uring).
- Caller and Receiver are not necessary in "Sync"

### Example of an OS asynchronous call (NodeJS)
- Program spins up a secondary thread.
- Secondary thread reads from disk, OS blocks it.
- Main program still running and executing code.
- Thread finishing reading and calls back main thread.

### Asynchronous workload is everywhere
- Asynchronous programming (promises/futures)
- Asynchronous backend processing.
- Asynchronous commit.
- Asynchronous IO in Linux (epoll, io_uring)
- Asynchronous replication.
- Asynchronous OS fsync (fs cache)

# Push
## Request/Response isn't always ideal
- Client wants real time notification from backend
  - A user just logged in
  - A message is just received
- Push model is good for above use cases.

## What is push?
- Client connects to a server
- Server sends data to the client
- Client doesn't have to request anything
- Protocol must be bidirectional
- Used by RabbitMQ

## Push pros and cons
- Pros:
  - Real time
- Cons:
  - Clients must be online to receive the push from the server.
  - Client might not be able to handle the load.
  - Requires a bidirectional protocol (WebSockets, HTTP/2 ...)
  - Polling is preferred for light clients.

# Short Polling
## What is Short Polling?
- Clients sends a request.
- Server responds immediately with a handle
- Server continues to process the request
- Client uses that handle to check for status (periodically, Client will continuously ask the server if there's anything new, such as new messages)
- Multiple "short" request response as polls

## Short Polling pros and cons
- Pros:
  - Simple
  - Good for long running requests
  - Client can disconnect (only with custom resuming techniques)
- Cons:
  - Too chatty (will congest the network)
  - Wasted backend resources.

# Long Polling
Request is taking long, I'll check with you later but talk to me only when it's ready.
## What is Long Polling?
- Clients sends a request.
- Server responds immediately with a handle
- Server continues to process the request
- Client uses that handle to check for status
- Server does not reply until it has the response
- Client polls the data at their leisure, timeout can be implemented (Kafka)
  - In Kafka, Consumers track the next offset they need to read from. This is often done in memory while the consumer is running. Consumers decide when to commit an offset and how frequently to do so.
  - When a consumer commits an offset, Kafka stores this information in a special internal topic named `__consumer_offsets`. The Kafka server is responsible for keeping track of these committed offsets. This allows consumers to pick up where they left off in the event of a restart or failure.

## Long Polling pros and cons
- Pros:
  - Less chatty and backend friendly
  - Client can still disconnect
- Cons:
  - Not real time

### Long polling vs Short polling
**Short Polling:**
- In short polling, the client sends a request to the server at regular intervals, regardless of whether there is new data to be retrieved.
- The server processes each request and responds immediately, whether or not there is new data. If there is no new data, the response might be empty or indicate that there is nothing new.
- After receiving a response, the client waits for a predetermined interval before sending another request.
- This can result in a high number of requests and responses, many of which may be unnecessary if there are no updates, leading to increased load on the server and network.

**Long Polling:**
- In long polling, the client sends a request to the server just like in short polling, but the server holds the request open until new data is available or a timeout occurs.
- If new data becomes available during this time, the server sends a response back to the client with the new data, and the client may immediately issue another request to wait for more updates.
- If no new data is available before the timeout, the server sends a response to close the request, and the client then immediately sends a new request to start waiting again.
- Long polling reduces the number of requests made when compared to short polling, as requests are only sent when the previous request is completed, which happens upon data availability or timeout.

# Publish Subcribe
A client publishes the data to the broker server and moves on. And other clients can consume the data from the broker server the data that was just published. Pub/sub is designed to solve the communication and dependency issues from the growing complexity of distributed systems by decoupling publishers from subscribers, allowing for asynchronous communication and scalable event-driven architectures.

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/87f5a716-9572-414f-a7b3-71d627bd47e6)

## Pub/Sub pros and cons
- Pros:
  - Scales w/ multiple receivers
  - Great for microservices
  - Losse coupling
  - Works while clients not running
- Cons:
  - Message delivery issues
    - How do I know that the subscribers (consumers) actually get the message?
    - Messages got consumed twice.
      - Kakfa's at least once guarantee ...
  - Complexity
  - Network Saturation (Since maybe a lot of consumers might try to poll from the same topic (or queue) from a broker server)
