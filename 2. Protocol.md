# Content
- [Protocol](#protocol)
- [OSI Model](#osi-model)
- [Internet Protocol](#internet-protocol)
- [ICMP](#icmp)
- [UDP](#udp)
- [TCP](#tcp)
- [TLS](#tls)
- [HTTP/1.1](#http11)
- [WebSockets](#websockets)
- [HTTP/2](#http2)
- [HTTP/3](#http3)
- [gRPC](#grpc)

# Protocol
## What is a protocol?
- A system that allows two parties to communicate
- A protocol is designed with a set of properties
- Depending on the purpose of the protocol
- TCP, UDP, HTTP, gRPC, FTP

## Protocol Properties
- **Data Format**
  - Text based (JSON, XML, plain text ...)
  - Binary (protobuf, HTTP2, HTTP3 ...)
- **Transfer mode**
  - Message based (UDP, HTTP)
  - Stream (TCP, WebRTC)
- **Addressing system**
  - DNS name, IP, MAC
- **Directionality**
  - Bidirectional (TCP)
  - Unidirectional (HTTP)
  - Full/Half Duplex
- **State**
  - Stateful (TCP, gRPC, Apache Thrift)
  - Stateless (HTTP, UDP)
- **Routing**
  - Proxies, Gateways

# OSI Model
## Why do we need a communication model?
- **Agnostic Applications**
  - Without a standard model, your application must have knowledge of the underlying network medium 
  - Imagine if you have to author different version of your apps so that it works on Wi-Fi vs ethernet vs LTE vs fiber 
- **Network Equipment Management**
  - Without a standard model, upgrading network equipments becomes difficult
- **Decoupled Innovation**
  - Innovations can be done in each layer separately without affecting the rest of the models 

## What is the OSI Model?
**7 Layers each describe a specific networking component** 
- Layer 7 - Application - HTTP/FTP/gRPC 
- Layer 6 - Presentation - Encoding, Serialization 
- Layer 5 - Session - Connection establishment, TLS 
- Layer 4 - Transport - UDP/TCP 
- Layer 3 - Network - IP 
- Layer 2 - Data link - Frames, Mac address Ethernet 
- Layer 1 - Physical - Electric signals, fiber or radio waves

**Example of sending a POST request to an HTTPS webpage**
- Layer 7 - Application 
  - POST request with JSON data to HTTPS server 
- Layer 6 - Presentation
  - Serialize JSON to flat byte strings
- Layer 5 - Session
  - Request to establish TCP connection/TLS 
- Layer 4 - Transport 
  - Sends SYN request target port 443
- Layer 3 - Network 
  - SYN is placed an IP packet(s) and adds the source/dest IPs
- Layer 2 - Data link
  - Each packet goes into a single frame and adds the source/dest MAC addresses 
- Layer 1 - Physical 
  - Each frame becomes string of bits which convened into either a radio signal (Wi-Fi), electric signal (ethernet), or light (fiber)

**Receiver computer receives the POST request the other way around**
- Layer 1 - Physical
  - Radio, electric or light is received and converted into digital bits
- Layer 2 - Data link
  - The bits from Layer 1 is assembled into frames
- Layer 3 - Network
  - The frames from layer 2 are assembled into IP packet
- Layer 4 - Transport
  - The IP packets from layer 3 are assembled into TCP segments
  - Deals with Congestion control/flow control/retransmission in case of TCP
  - If Segment is SYN we don't need to go further into more layers as we are still processing the connection request
- Layer 5 - Session
  - The connection session is established or identified
  - We only arrive at this layer when necessary (three-way handshake is done)
- Layer 6 - Presentation
  - Deserialize flat byte stings back to JSON for the app to consume
- Layer 7 - Application
  - Application understands the JSON POST request and your express json or apache request receive event is triggered 

## The shortcomings of the OSI Model
- OSI Model has too many layers which can be hard to comprehend
- Hard to argue about which layer does what
- Simpler to deal with Layers 5-6-7 as just one layer (Application layer) which the TCP/IP model does just that.

## TCP/IP Model
- Much simpler than OSI just 4 layers
- Application (Layer 5,6 and 7)
- Transport (Layer 4)
- Internet (Layer 3)
- Data Link (Layer 2)
- Physical layer if not officially part of the model

# Internet Protocol
## IP Packet
- The IP Packet has headers and data sections
- IP Packet header is 20 bytes (can go up to 60 bytes if options are enabled)
- Data section can go up to 65536

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/c358976a-ee42-4eb3-91cb-3ca739201731)

When you send an HTTP request, the entire HTTP message, including the header, body, and any other associated data, is encapsulated within the data section of the TCP segment.

# ICMP
## What is ICMP?
ICMP is a protocol that operates at the network layer of the TCP/IP protocol stack. It is designed to facilitate communication between network devices and provide feedback about the health and status of network connections.
- Stands for Internet Control Message Protocol
- Designed for informational messages
  - Host unreachable, port unreachable, fragmentation needed
  - Packet expired (infinite loop in routers)
- Uses IP directly
- PING and traceroute use it
- Doesn't require listeners or ports to be opened

## Problems with ICMP
- Some firewalls block ICMP for security reasons, some routers between hops might drop IMCP.
- That is why PING might not work in those cases
- Disabling ICMP also can cause real damage with connection establishment
  - Fragmentation needed

# UDP
- Stands for User Datagram Protocol
- Layer 4 protocol
- Ability to address processes in a host using ports
- Simple protocol to send and receive data
- Prior communication not required (double edge sword)
- Stateless no knowledge is stored on the host
- 8 byte header Datagram

## UDP Use cases
**Ideal when you don't care about consistency all the time**
- Video Streaming
  - You don't care if some of the video data frames are dropped.
- VPN
  - Utilize UDP for reduced overhead and increased speed, prioritizing performance over TCP's reliability.
- DNS
  - DNS transactions, being lightweight and time-sensitive, opt for UDP due to its connectionless nature, allowing for faster query responses.
- WebRTC
  - WebRTC relies on UDP for low latency and real-time performance in applications like video conferencing, favoring responsiveness over guaranteed data delivery.
 
## UDP Datagram
- UDP Header is 8 bytes only (IPv4)
- Datagram slides into an IP packet as "data"
- Port are 16 bit (0 to 65535)

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/97d000af-0543-427c-90f9-0228c5b30c03)

## UDP Pros and Cons
- Pros
  - Simple protocol
  - Header size is small so datagrams are small
  - Uses less bandwidth
  - Stateless
  - Consumes less memory (no state stored in the server/client)
  - Low latency - since there is no handshake, order, retransmission or gaaranteed delivery.
 
- Cons
  - No acknowledgement
  - No guarantee delivery
  - Connection-less - anyone can send data without prior knowledge
  - No flow control
  - No congestion control
  - No ordered packets
  - Security - can be easily spoofed

# TCP
- Stands for Transmission COntrol Protocol
- Layer 4 protocol
- Ability to address processes in a host using ports
- "Controls" the trnasmission unlike UDP which is a firehose
- Conneciton
- Requires Handshake
- 20 bytes headers Segment (can go to 60)
- Stateful

## TCP Uses cases
- Reliable communication
- Remote shell
- Datebase connections
- Web communications
- Any bidirectional communication

## TCP Connection
- Connection is a Layer 5 (session) 
- Connection is an agreement between client and server
- Must create a connection to send data
- Connection is identified by 4 properties
  - SourceIP-SourcePort
  - DestinationIP-DestinationPort
- Can’t send data outside of a connection
- Sometimes called socket or file descriptor
- Requires a 3-way TCP handshake
- Segments are sequenced and ordered
- Segments are acknowledged
- Lost segments are retransmitted 

## TCP in Depth
### Connection Establishment
- App1 on 10.0.0.1 want to send data to AppX on 10.0.0.2 
- App1 sends SYN to AppX to synchronous sequence numbers
- AppX sends SYN/ACK to synchronous its sequence number
- App1 ACKs AppX SYN.
- Three way handshake

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/d8e7267e-6177-4aeb-ba0b-05bbabae0a4a)

### Sending data
- App1 sends data to AppX
- App1 encapsulate the data in a segment and send it
- AppX acknowledges the segment
- Hint: Can App1 send new segment before ack of old segment arrives?

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/b5cbaec6-5130-407f-8cf1-99cc09b0e002)

### Acknowledgement
- App1 sends segment 1,2 and 3 to AppX
- AppX acknowledge all of them with a single ACK 3

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/9bb168fe-5b6a-429c-ad7f-e0ccc64f1938)

### Lost data
- App1 sends segment 1,2 and 3 to AppX
- Seg 3 is lost, AppX acknowledge 3
- App1 resend Seq 3

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/6263941f-9b40-4168-8162-ed67f2ce2112)

### Closing Connection
- App1 wants to close the connection
- App1 sends FIN, AppX ACK
- AppX sends FIN, App1 ACK
- Four way handshake

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/fdfc2118-42d8-421f-af3e-ea7426d65d5c)

## TCP Pros and Cons
- Pros
  - Guarantee delivery
  - No one can send data without prior knowledge
  - Flow Control and Congestion Control
  - Ordered Packets no corruption or app level work
  - Secure and can’t be easily spoofed
 
- Cons
  - Large header overhead compared to UDP
  - More bandwidth
  - Stateful - consumes memory on server and client 
  - Considered high latency for certain workloads (Slow start/ congestion/ acks)
  - Does too much at a low level (hence QUIC)
    - Single connection to send multiple streams of data (HTTP requests)
    - Stream 1 has nothing to do with Stream 2
    - Both Stream 1 and Stream 2 packets must arrive
  - TCP Meltdown
    - Not a good candidate for VPN

# TLS
[TLS](https://github.com/boushphong/Practical-Networking/blob/master/9.%20SSL%20&%20TLS.md)

# HTTP/1.1
## Anatomy of an HTTP Request
- **Method**, **PATH**, **Protocol**
- **Headers**
- **Body**

## Anatomy of an HTTP Response
- **Protocol**, **Code**, **Code Text**
- **Headers**
- **Body**

## HTTP 1.0
- New TCP connection with each request
  - Slow
- Buffering (transfer-encoding:chunked didn’t exist)
- No multi-homed websites (HOST header)

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/c2cbb339-9a88-4f62-beec-b66e91b09c0f)

## HTTP 1.1
- Persisted TCP Connection
- Low Latency & Low CPU Usage
- Streaming with Chunked transfer
- Pipelining (disabled by default)
- Proxying & Multi-homed websites

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/04fd4b22-bb8d-454a-98bc-74e22052415b)

## HTTP 1.1 Pipelining
![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/a894e042-38e8-4208-b129-8df3906ec1d4)

# WebSockets
Bidirectional communications on the web

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/c2b69650-f86f-47f6-b144-8761e8a40451)

## How does WebSockets work?
1. **HTTP Handshake**: WebSocket connections start with an HTTP/1.1 handshake, which is used to negotiate and upgrade the connection to the WebSocket protocol. This handshake occurs over a standard HTTP connection. The client sends an HTTP request with an Upgrade header indicating its desire to switch protocols to WebSocket. If the server supports WebSocket and agrees to the upgrade, it responds with an HTTP 101 (Switching Protocols) status code and includes headers indicating the WebSocket protocol.

2. **Switch to WebSocket Protocol**: Upon receiving the 101 response, both the client and server switch from the HTTP protocol to the WebSocket protocol. From this point onwards, the communication between the client and server occurs using the WebSocket protocol, which operates over a single, full-duplex TCP connection.

3. **WebSocket Communication**: Once the WebSocket connection is established, the client and server can exchange messages bidirectionally in real-time without the overhead of HTTP request/response headers. WebSocket allows for low-latency, full-duplex communication, making it suitable for applications such as real-time chat, online gaming, and live data streaming.

![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/de0a21c1-efdf-42ce-90f5-f460e9ed950c)

## Websocket Handshake
**Client**
```HTTP
GET /chat HTTE/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMIDDL1E.Lkh9GHhXDw==
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13
Origin: http://example.com 
```

**Server**
```HTTP
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: HSmrcOsM1YUkAGmm5OPpG2HaGWk=
Sec-WebSocket-Protocol: chat 
```

## WebSockets use cases
- Chatting
- Live Feed
- Multiplayer gaming
- Showing client progress/logging

## WebSockets Pros and Cons
- Pros:
  - Full-duplex (no polling)
  - HTTP compatible
  - Firewall friendly
- Cons:
  - Proxying is tricky
  - L7 LB challenging (timeouts)
  - Stateful, difficult to horizontally scale

# HTTP/2
- Compression (Headers & Data)
- Multiplexing
- Server Push
- Secure by default
- Protocol Negotiation during TLS (NPN/ALPN)

## HTTP/2 Pros and Cons
**Pros:**
1. **Multiplexing**: In HTTP/1.1, each request-response cycle typically requires a separate TCP connection, which can lead to inefficiencies, especially for websites with many small assets. HTTP/2 introduces multiplexing, allowing multiple requests and responses to be sent and received concurrently over a single TCP connection. This significantly reduces latency and improves the utilization of network resources.
    - **HTTP/1.1 Multiplexing**: If a webpage contains multiple resources (HTML, CSS, JavaScript, images, etc.), each resource requires its own separate TCP connection to the server. These connections are typically opened and closed for each resource, leading to inefficiencies, especially for websites with many small assets.
    - **HTTP/2 Multiplexing**: If a webpage requires several resources, such as HTML, CSS, JavaScript, and images, all of these resources can be requested simultaneously over the same TCP connection. The server can respond to these requests in any order, and the responses are then reassembled in the correct order by the client.
    - Multiplexing in HTTP/2 significantly reduces latency and improves the utilization of network resources because it avoids the overhead of establishing multiple TCP connections for each resource. It also eliminates the head-of-line blocking problem associated with HTTP/1.1, where slow responses to one resource can delay the loading of subsequent resources. Additionally, multiplexing allows for better resource prioritization, as clients can assign priorities to individual streams within the same connection, ensuring that critical resources are delivered first.
2. **Header Compression**: HTTP/2 employs header compression techniques to reduce the overhead of HTTP headers, which can be significant, especially for small requests or responses. This helps to further reduce latency and improve the efficiency of data transmission
3. **Server Push**: HTTP/2 introduces server push, a feature that allows servers to proactively send resources to clients before they are requested. This can improve the loading speed of web pages by allowing servers to push critical resources such as CSS, JavaScript, and images to clients, reducing the need for additional round trips.
4. **Stream Prioritization**: HTTP/2 allows clients to assign priorities to individual streams within a single TCP connection, enabling more efficient resource allocation and ensuring that critical resources are delivered first. This helps to improve the overall performance and responsiveness of web applications.
5. **Binary Protocol**: HTTP/2 is a binary protocol, whereas HTTP/1.1 is a text-based protocol. The binary format of HTTP/2 allows for more efficient parsing and processing by both clients and servers, resulting in better performance and reduced overhead.
6. **TLS Encouraged**: While HTTPS (HTTP over TLS) is optional in HTTP/1.1, it is strongly encouraged in HTTP/2. This helps to ensure the security and privacy of data transmitted over the network.

**Cons:**
1. **Head-of-Line Blocking**: While multiplexing can help alleviate head-of-line blocking to some extent compared to HTTP/1.1, it can still occur within the HTTP/2 connection. If a particular stream (e.g., a large file) experiences congestion or delays, it can potentially block the transmission of other streams sharing the same connection.
2. **Resource Contention**: With multiplexing, multiple streams compete for resources within the same TCP connection. This can lead to contention for bandwidth, CPU, and memory resources on both the client and server. In cases of high concurrency or heavy load, this contention may impact the performance of individual streams and the overall connection.

# HTTP/3
## Problems with Head-of-Line in HTTP/2
![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/2e44c4b0-402a-4ed6-894f-128170bfc059)

In HTTP/2, if segment 3 of **main.css** was lost, every stream to be delivered after stream 2 would be blocked.

## HTTP/3 & QUIC
- HTTP/3 uses QUIC
- Like HTTP/2, QUIC has streams
- But QUIC use UDP instead
- Application decides the boundary

### HTTP/3 Stream
![image](https://github.com/boushphong/BE-Fundamentals/assets/59940078/31b3e8ab-ff59-476c-901c-11e84dbd595a)

All segments (actually called **datagrams**) in HTTP/3 are all independent UDP.

## HTTP/3 Pros and Cons
- Pros
  - Merges Connection setup + TLS in one handshake
  - Has congestion control at stream level
  - Connection migration (connectionID)
  - Why not HTTP/2 over QUIC?
    - Header compression algorithm
 
- Cons
  - Takes a lot of CPU (parsing logic)
    - Additional processing required for encryption, decryption, and protocol handling in QUIC
  - UDP could be blocked
  - MTU (Maximum Transmission Unit) consideration
    - Different types of network technologies, such as Ethernet, Wi-Fi, and PPP, have different MTU sizes. HTTP/3 relies on UDP as its transport protocol, and UDP packets may still be subject to IP fragmentation if they exceed the Maximum Transmission Unit (MTU) of a network segment. Large UDP packets, especially those containing QUIC (the underlying protocol of HTTP/3) data, may be fragmented if they encounter network segments with smaller MTU sizes.

# gRPC





















